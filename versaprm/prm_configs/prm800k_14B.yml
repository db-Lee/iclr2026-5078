model_id: 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B'

# ─── Data ────────────────────────────────────────────────────
train_data_path: './local_datasets/train'
eval_data_path: null
max_length: 7650
train_label_last_n: 1
eval_label_last_n: 1
task_type: "prm"
no_balance: true

# ─── Tracking ────────────────────────────────────────────────
wandb_project: 'versaprm'

# ─── Hugging Face Trainer arguments ──────────────────────────
lora_config:
  r: 16
  lora_alpha: 32
  lora_dropout: 0.1
  target_modules: 'all-linear'
  task_type: 'CAUSAL_LM'

training_args:
  output_dir: null

  # ─ Optimization ─
  learning_rate: 1.0e-4
  num_train_epochs: 1
  effective_batch_size: 16
  lr_scheduler_type: cosine
  warmup_ratio: 0.1
  weight_decay: 0.01
  bf16: true

  # ─ Logging ─
  logging_strategy: steps
  logging_steps: 1

  # ─ Checkpointing ─
  save_strategy: "no"

  # ─ Hub push disabled ─
  push_to_hub: false

  # ─ Reproducibility ─
  seed: 908932403
  data_seed: 289245

  # ─ Misc ─
  use_liger_kernel: true
  gradient_checkpointing: true
  ddp_find_unused_parameters: false